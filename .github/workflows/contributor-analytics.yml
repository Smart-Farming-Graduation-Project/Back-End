name: Contributor Analytics

on:
  schedule:
    - cron: '0 0 * * *'  # Runs daily at midnight UTC
  workflow_dispatch:  # Allows for manual triggering

jobs:
  contributor_analytics:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python environment
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip install pandas matplotlib requests

      - name: Fetch Contributor Data
        env:
          GITHUB_TOKEN: ${{ secrets.Token_Test }}
        run: |
          python3 -c "
import requests
import json
from datetime import datetime

# Set up GitHub API endpoint and headers
url = 'https://api.github.com/repos/YOUR_ORG/YOUR_REPO/stats/contributors'
headers = {'Authorization': f'Bearer {GITHUB_TOKEN}'}
response = requests.get(url, headers=headers)

# Check if response is valid
if response.status_code != 200:
    raise Exception(f'Error fetching data: {response.status_code}')

data = response.json()

# Process data for easier analytics
analytics_data = {'timestamp': datetime.utcnow().isoformat(), 'data': {}}
for contributor in data:
    user = contributor['author']['login']
    analytics_data['data'][user] = {
        'commits': contributor['total'],
        'issues': 0,  # Replace with actual data if available
        'pull_requests': 0  # Replace with actual data if available
    }

# Save data to file
with open('contributor_analytics.json', 'w') as f:
    json.dump([analytics_data], f)
"

      - name: Generate visualizations
        run: |
          python3 -c "
import matplotlib
matplotlib.use('Agg')  # Use a non-interactive backend suitable for headless environments

import json
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

# Load and process the data
with open('contributor_analytics.json', 'r') as f:
    all_data = json.load(f)

records = []
for entry in all_data:
    for user, contributions in entry['data'].items():
        record = {
            'timestamp': entry['timestamp'],
            'user': user,
            'commits': contributions['commits'],
            'issues': contributions['issues'],
            'pull_requests': contributions['pull_requests']
        }
        records.append(record)

df = pd.DataFrame(records)
df['timestamp'] = pd.to_datetime(df['timestamp'])

# Generate total contributions over time chart
total_contributions = df.groupby('timestamp')[['commits', 'issues', 'pull_requests']].sum()
total_contributions.plot(kind='line', figsize=(10, 5))
plt.title('Total Contributions Over Time')
plt.xlabel('Date')
plt.ylabel('Number of Contributions')
plt.savefig('total_contributions.png')

# Generate contributions by user chart
user_contributions = df.groupby('user')[['commits', 'issues', 'pull_requests']].sum()
user_contributions.plot(kind='bar', stacked=True, figsize=(10, 5))
plt.title('Contributions by User')
plt.xlabel('User')
plt.ylabel('Number of Contributions')
plt.savefig('contributions_by_user.png')
"

      - name: Upload visualizations as artifacts
        uses: actions/upload-artifact@v3
        with:
          name: contributor-analytics-visualizations
          path: |
            total_contributions.png
            contributions_by_user.png
